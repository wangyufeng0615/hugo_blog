---
title: "GPT 对封闭知识的局限性"
date: 2023-03-20T00:00:00+08:00
draft: false
---

今天感受到了一个ChatGPT的局限性。

例如，对于RPC框架，腾讯内部会使用tRPC，而对于外部公司或团队来说，会用gRPC或是别的什么更通用的东西。可以设想的是，ChatGPT很难对公司内部的tRPC的使用，给出什么可靠的建议，因为这些tRPC相关的文档、代码，是封闭在内部的。当然，腾讯也可以开发自己的大模型，学习内部的知识，但效果肯定不如学习了互联网海量信息的模型。

我的第一反应是，这是ChatGPT的局限性，但展开想一想的话，我会觉得这是这种内部技术自身的局限性。因为，比如说对于使用gRPC的用户，他可以用ChatGPT去询问很多关于gRPC的用法，甚至直接代写代码。这两者的生产力效率会有越来越大的差距。我相信这里存在马太效应，越是主流的知识，在AIGC工具的加持下，越容易巩固主流地位。

可是，“足够稀缺的经验”不也是一种封闭的知识吗？那该怎么判断，哪种“封闭”的知识在AIGC的时代，是具有足够的价值的呢？我想到一条很简单的判断标准：

1. 如果这些知识在外部具有足够多的需求，外部想要打破这种封闭性，甚至加入其中成为其垄断机制的一部分，这些封闭的知识则会增值。


例如，我掌握了全国数一数二的九转大肠的烹饪秘籍。

2. 如果这些知识在外部没什么真实的需求，只是因为种种原因而诞生的封闭性，这种知识则会愈发没有价值。

例如，我曾经在一家公司工作，那里的报销流程相当复杂，这些知识也是封闭的、需要学习的、学习后对工作有价值的。只是，只要换了个环境，我就发现这些知识毫无意义。

甚至，在可预见的未来，ChatGPT和其他AIGC的能力，也帮不上这些效率什么忙。造成这种低效局面的，不是工具的原因，自然也不会被更好的工具所改善。